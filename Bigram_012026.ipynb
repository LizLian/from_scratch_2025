{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6gvv+dXJRSyYvH9Jx4z/u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LizLian/from_scratch_2025/blob/main/Bigram_012026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBIoOcdMXLlz"
      },
      "outputs": [],
      "source": [
        "# @title Bigram Template"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Read in the name.txt file, build a dictionary to store the bigram and their count from the dataset.\n",
        "2. Sample from the model. Steps when encounters the end of sentence symbol.\n",
        "3. write the negative log likelihood loss function. (cross entropy).\n",
        "4. convert the bigram model to neural net. (hint: convert x to one hot vectors, initialize weights, logits = xenc @ W. Update W.data in backward pass)\n",
        "5. sample the model again to see the results after optimization."
      ],
      "metadata": {
        "id": "We1bDvZJYkuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open(\"names.txt\") as infile:\n",
        "  for line in infile:\n",
        "    data.append(line.strip())"
      ],
      "metadata": {
        "id": "kgXot2Ojcj7D"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgdqgJTCgnZt",
        "outputId": "f0a0fd49-ad7b-4bf1-abaa-fcfdc742e035"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(\".\".join(data))"
      ],
      "metadata": {
        "id": "nLxChdV4p2Q7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {}\n",
        "itos = {}\n",
        "for i, c in enumerate(sorted(vocab)):\n",
        "  stoi[c] = i\n",
        "  itos[i] = c\n"
      ],
      "metadata": {
        "id": "jR_qEVw0qawP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams = torch.zeros((len(vocab), len(vocab)))\n",
        "for name in data:\n",
        "  chrs = \".\" + name + \".\"\n",
        "  for ch1, ch2 in zip(chrs, chrs[1:]):\n",
        "    bigrams[stoi[ch1], stoi[ch2]] += 1"
      ],
      "metadata": {
        "id": "bXKqDWo3g2k6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sample from the model\n",
        "start_chr_prob = bigrams[0].float()/bigrams[0].sum()\n",
        "start_chr_prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtgDswM3rO3G",
        "outputId": "18f7c29a-b444-47a2-ab27-77348918c126"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
              "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
              "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "for i in range(5):\n",
        "  ix = 0\n",
        "  out = []\n",
        "  while True:\n",
        "    p = bigrams[ix].float()/bigrams[ix].sum()\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    c = itos[ix]\n",
        "    out.append(c)\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(\"\".join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wz4R6T6rk-2",
        "outputId": "2c8ab8d0-16b0-4201-f9c8-8c3812e8452c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cexze.\n",
            "momasurailezitynn.\n",
            "konimittain.\n",
            "llayn.\n",
            "ka.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Negative Log likelihood\n",
        "nll = -torch.log(p).sum()\n",
        "nll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IkTIYz85bne",
        "outputId": "e0f562ff-55a7-4357-8e1c-c5ed9d52d3c9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(109.1046)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "for name in data:\n",
        "  chrs = \".\" + name + \".\"\n",
        "  for ch1, ch2 in zip(chrs, chrs[1:]):\n",
        "    xs.append(stoi[ch1])\n",
        "    ys.append(stoi[ch2])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "num = xs.nelement()\n",
        "ys = torch.tensor(ys)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True) # random select from a normal distribution (mean=0, std=1)\n",
        "\n",
        "for i in range(100): # 50 epochs\n",
        "  xenc = F.one_hot(xs, num_classes=27).float()\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts/counts.sum(dim=1, keepdim=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  if i%10==0:\n",
        "    print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -70 * W.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMMVrn_X_uGQ",
        "outputId": "fc4e0f7c-438c-4172-9362-42a24e0deb79"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.625509023666382\n",
            "2.6165945529937744\n",
            "2.5435054302215576\n",
            "2.5182595252990723\n",
            "2.5057497024536133\n",
            "2.4984216690063477\n",
            "2.493731737136841\n",
            "2.4905762672424316\n",
            "2.4883792400360107\n",
            "2.486804962158203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model Generate Function\n",
        "for i in range(5):\n",
        "  ix = 0\n",
        "  out = []\n",
        "  while True:\n",
        "    # p = bigrams[ix].float()/bigrams[ix].sum()\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    p = counts/counts.sum(dim=1, keepdim=True)\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    c = itos[ix]\n",
        "    out.append(c)\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(\"\".join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm8zxriqEiFZ",
        "outputId": "bdd6da07-02be-47fe-e0f8-f702fd8626ca"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ckae.\n",
            "a.\n",
            "hidaruyia.\n",
            "ezera.\n",
            "duillpwghanamahu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m6Mz0YziIwqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}